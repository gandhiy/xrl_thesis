{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.DQN import DQNAgent\n",
    "from models.policies import MlpPolicy\n",
    "from models.reward_functions import Identity, additive_SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashgandhi/Documents/xrl_thesis/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "env._max_episode_steps = 100 # shorter steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQNAgent(env, \n",
    "                 MlpPolicy, \n",
    "                 additive_SHAP, \n",
    "                 memory_size = 50000, \n",
    "                 batch_size=256, \n",
    "                 update_timesteps=256, \n",
    "                 logger_steps=100, \n",
    "                 learning_starts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 3 \t Average Reward -99.6667 \t Loss: 0.0003 \t Timesteps: 300\n",
      "Episodes: 1 \t Average Reward -99.7500 \t Loss: 0.0004 \t Timesteps: 400\n",
      "Episodes: 1 \t Average Reward -99.8000 \t Loss: 0.0002 \t Timesteps: 500\n",
      "Episodes: 1 \t Average Reward -99.8333 \t Loss: 0.0007 \t Timesteps: 600\n",
      "Episodes: 1 \t Average Reward -99.8571 \t Loss: 0.0008 \t Timesteps: 700\n",
      "Episodes: 1 \t Average Reward -99.8750 \t Loss: 0.0005 \t Timesteps: 800\n",
      "Episodes: 1 \t Average Reward -99.8889 \t Loss: 0.0005 \t Timesteps: 900\n",
      "Episodes: 1 \t Average Reward -99.9000 \t Loss: 0.0005 \t Timesteps: 1000\n"
     ]
    }
   ],
   "source": [
    "model.learn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 with reward -100.0\n",
      "Episode 2 with reward -100.0\n",
      "Episode 3 with reward -100.0\n",
      "Episode 4 with reward -100.0\n",
      "Episode 5 with reward -100.0\n"
     ]
    }
   ],
   "source": [
    "model.create_gif(save=\"mountain_car_shap\", frames=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
